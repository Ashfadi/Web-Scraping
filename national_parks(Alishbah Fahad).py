# -*- coding: utf-8 -*-
"""National_Parks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yX7elUtWLqNtPWkKbsw5OkDHdhdMqZZ6

# Importing Libraries
"""

import pandas as pd
import requests
from bs4 import BeautifulSoup as bs

"""# Retrieving the page with the drop-down list"""

r=requests.get("https://www.nps.gov/index.htm")
soup=bs(r.content,'html.parser')
print(soup.prettify())

"""### Retrieving the drop-down list"""

s=soup.find("ul",attrs={"class":"dropdown-menu SearchBar-keywordSearch"})
print(s.prettify())

"""# Retrieving the links to all states from page 1 (List of States)"""

states=s.select("a")
Links=[link['href'] for link in states]
df=pd.DataFrame(states,columns=['Name of States'])
df1=pd.DataFrame(Links,columns=['Links for States'])
list_of_states=pd.merge(df,df1,left_index=True,right_index=True)
list_of_states.to_csv('list_of_states.csv',index=False)
list_of_states

"""# Retrieving each state’s page """

url = 'https://www.nps.gov'
for link in Links:
  res = requests.get(url + link)
  Page = bs(res.content, 'html.parser')

"""# Retrieving the list of all parks from page 2 for each state (List of Parks)"""

url = 'https://www.nps.gov'
list_of_parks = []
for link in Links:
  res = requests.get(url + link)
  Page = bs(res.content, 'html.parser')
  parks = Page.find("ul",{"id":"list_parks"}).find_all("li",{"class":"clearfix"})
  for eachpark in parks:
    park = {}
    park['List of Parks'] = eachpark.find('h3').getText()
    list_of_parks.append(park)
df2=pd.DataFrame(list_of_parks,columns=['List of Parks'])
df2.to_csv('List_of_Parks.csv',index=False)
df2

"""# Retrieving each park’s name, category, and description from the above list of parks in each state"""

url = 'https://www.nps.gov'
Parks_Info = []
for link in Links:
  res = requests.get(url + link)
  Page = bs(res.content, 'html.parser')
  parks = Page.find("ul",{"id":"list_parks"}).find_all("li",{"class":"clearfix"})
  for eachpark in parks:
    park = {}
    park['Name'] = eachpark.find('h3').getText()
    park['Category'] = eachpark.find('h2').getText()
    park['Description'] = eachpark.find('p').getText().replace('\n','')
    Parks_Info.append(park)
df3=pd.DataFrame(Parks_Info,columns=['Name','Category','Description'])
df3.to_csv('Parks_Info.csv',index=False)
df3

"""# Retrieving each park’s page"""

url = 'https://www.nps.gov'
Parks_Links = []
for link in Links:
  res = requests.get(url + link)
  Page = bs(res.content, 'html.parser')
  parks = Page.find("ul",{"id":"list_parks"}).find_all("li",{"class":"clearfix"})
  for eachpark in parks:
    park = {}
    park = eachpark.find('h3').findChild('a')['href']
    Parks_Links.append(str(park))
df4=pd.DataFrame(Parks_Links,columns=['Parks_Links'])
df4.to_csv('Parks_Links.csv',index=False)
df4

"""# Retrieving each park’s contact information from page 3 for each park"""

url = 'https://www.nps.gov'
Parks_Data=[]
for links in Parks_Links:
  L = requests.get(url + links)
  bs_page = bs(L.content, 'html.parser')
  pages=bs_page.find_all('div',attrs={'class':'vcard'})
  for eachpage in pages:
    parkdata={}
    Address = eachpage.find("span",attrs={"class":"street-address"})
    if Address:
      addresstxt = Address.getText()
      address_lines = addresstxt.splitlines()
      parkdata['Street Address Line 1'] = len(address_lines)>1 and address_lines[1] or 'null'
      parkdata['Line 2'] = len(address_lines)>2 and address_lines[2] or 'null'
      parkdata['Line 3'] = len(address_lines)>3 and address_lines[3] or 'null'
    City=eachpage.find('span',attrs={'itemprop':'addressLocality'})
    if City:
      parkdata['City']=City.getText()
    State=eachpage.find('span',attrs={'class':'region'})
    if State:
      parkdata['State']=State.getText()
    Zip_Code=eachpage.find('span',attrs={'class':'postal-code'})
    if Zip_Code:
      parkdata['Zip Code']=Zip_Code.getText()
    Phone_Number=eachpage.find('span',attrs={'class':'tel'})
    if Phone_Number:
      parkdata['Phone Number']=Phone_Number.getText().replace('\n','')
    Parks_Data.append(parkdata)
df5=pd.DataFrame(Parks_Data,columns=['Street Address Line 1','Line 2','Line 3','City','State','Zip Code','Phone Number'])
All_Parks_Data=pd.merge(df3,df5,left_index=True,right_index=True)
All_Parks_Data.to_csv('All_Parks_Data.csv',index=False)
All_Parks_Data